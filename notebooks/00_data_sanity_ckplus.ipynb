{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a93407d",
   "metadata": {},
   "source": [
    "Prove your splits are valid (no overlaps, no missing files, images load, and there aren’t obvious duplicates/leaks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07023a44",
   "metadata": {},
   "source": [
    "Checking for the CWD just to see if I should use relative paths or absolute paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5e7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _bootstrap import bootstrap\n",
    "bootstrap()\n",
    "\n",
    "from xai_lab.utils.paths import find_project_root, resolve_path\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4e297",
   "metadata": {},
   "source": [
    "Checking import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903bd5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# ---- Adjust these if your split filenames/paths differ ----\n",
    "SPLITS_DIR = Path(\"../data/processed/ckplus/splits\")  # notebook is in notebooks/, so ../\n",
    "TRAIN_CSV = SPLITS_DIR / \"train.csv\"\n",
    "VAL_CSV   = SPLITS_DIR / \"val.csv\"\n",
    "TEST_CSV  = SPLITS_DIR / \"test.csv\"\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"../artifacts/reports/eda\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(TRAIN_CSV.exists(), VAL_CSV.exists(), TEST_CSV.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b2013",
   "metadata": {},
   "source": [
    "Load splits and validate schema to check for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff57c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>mode</th>\n",
       "      <th>sha1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw/ckplus/happy/S078_004_00000027.png</td>\n",
       "      <td>4</td>\n",
       "      <td>happy</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>L</td>\n",
       "      <td>b8cf9e957093b01e482005a1c47c514c72861e28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw/ckplus/sadness/S080_005_00000011.png</td>\n",
       "      <td>5</td>\n",
       "      <td>sadness</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>L</td>\n",
       "      <td>54c7b1b5cf50c23cda4b4b6fe76fed4ffb639374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw/ckplus/happy/S100_006_00000015.png</td>\n",
       "      <td>4</td>\n",
       "      <td>happy</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>L</td>\n",
       "      <td>5382e1c188577cb99e0d8c1c06f5551600ddb152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/raw/ckplus/sadness/S138_007_00000009.png</td>\n",
       "      <td>5</td>\n",
       "      <td>sadness</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>L</td>\n",
       "      <td>9168e33c06eaf8bd31c87efb42c8e915604bfa3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/raw/ckplus/anger/S050_004_00000021.png</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>L</td>\n",
       "      <td>ba8ea832e8c1feaf480996a441bafff3f172923b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  label label_name  width  \\\n",
       "0    data/raw/ckplus/happy/S078_004_00000027.png      4      happy     48   \n",
       "1  data/raw/ckplus/sadness/S080_005_00000011.png      5    sadness     48   \n",
       "2    data/raw/ckplus/happy/S100_006_00000015.png      4      happy     48   \n",
       "3  data/raw/ckplus/sadness/S138_007_00000009.png      5    sadness     48   \n",
       "4    data/raw/ckplus/anger/S050_004_00000021.png      0      anger     48   \n",
       "\n",
       "   height mode                                      sha1  \n",
       "0      48    L  b8cf9e957093b01e482005a1c47c514c72861e28  \n",
       "1      48    L  54c7b1b5cf50c23cda4b4b6fe76fed4ffb639374  \n",
       "2      48    L  5382e1c188577cb99e0d8c1c06f5551600ddb152  \n",
       "3      48    L  9168e33c06eaf8bd31c87efb42c8e915604bfa3a  \n",
       "4      48    L  ba8ea832e8c1feaf480996a441bafff3f172923b  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 686 147 148\n"
     ]
    }
   ],
   "source": [
    "def load_split(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "train_df = load_split(TRAIN_CSV)\n",
    "val_df   = load_split(VAL_CSV)\n",
    "test_df  = load_split(TEST_CSV)\n",
    "\n",
    "display(train_df.head())\n",
    "\n",
    "required_cols = {\"path\", \"label\", \"label_name\"}\n",
    "for name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    missing = required_cols - set(df.columns)\n",
    "    assert not missing, f\"{name} is missing columns: {missing}\"\n",
    "\n",
    "print(\"Loaded:\", len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943d041",
   "metadata": {},
   "source": [
    "Basic integrity: counts + obvious nulls. There should be no NaNs and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917dd0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== train ==\n",
      "label         0\n",
      "label_name    0\n",
      "dtype: int64\n",
      "Unique labels: 7\n",
      "Unique label_names: 7\n",
      "Unique paths: 686  / total rows: 686\n",
      "\n",
      "== val ==\n",
      "label         0\n",
      "label_name    0\n",
      "dtype: int64\n",
      "Unique labels: 7\n",
      "Unique label_names: 7\n",
      "Unique paths: 147  / total rows: 147\n",
      "\n",
      "== test ==\n",
      "label         0\n",
      "label_name    0\n",
      "dtype: int64\n",
      "Unique labels: 7\n",
      "Unique label_names: 7\n",
      "Unique paths: 148  / total rows: 148\n"
     ]
    }
   ],
   "source": [
    "def basic_checks(name, df):\n",
    "    print(f\"\\n== {name} ==\")\n",
    "    print(df[[\"label\", \"label_name\"]].isna().sum())\n",
    "    print(\"Unique labels:\", df[\"label\"].nunique())\n",
    "    print(\"Unique label_names:\", df[\"label_name\"].nunique())\n",
    "    print(\"Unique paths:\", df[\"path\"].nunique(), \" / total rows:\", len(df))\n",
    "\n",
    "basic_checks(\"train\", train_df)\n",
    "basic_checks(\"val\", val_df)\n",
    "basic_checks(\"test\", test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a6474",
   "metadata": {},
   "source": [
    "File existence confirmation on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a7f4302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files: 0 0 0\n"
     ]
    }
   ],
   "source": [
    "def find_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    paths = df[\"path\"].astype(str).map(resolve_path)\n",
    "    exists = paths.map(lambda p: p.exists())\n",
    "    missing_df = df.loc[~exists].copy()\n",
    "    missing_df[\"resolved_path\"] = paths.loc[~exists].astype(str)\n",
    "    return missing_df\n",
    "\n",
    "missing_train = find_missing(train_df)\n",
    "missing_val   = find_missing(val_df)\n",
    "missing_test  = find_missing(test_df)\n",
    "\n",
    "print(\"Missing files:\", len(missing_train), len(missing_val), len(missing_test))\n",
    "\n",
    "if len(missing_train) + len(missing_val) + len(missing_test) > 0:\n",
    "    issues = pd.concat([\n",
    "        missing_train.assign(split=\"train\"),\n",
    "        missing_val.assign(split=\"val\"),\n",
    "        missing_test.assign(split=\"test\"),\n",
    "    ])\n",
    "    issues.to_csv(ARTIFACTS_DIR / \"missing_files.csv\", index=False)\n",
    "    display(issues.head(20))\n",
    "    print(\"Saved:\", ARTIFACTS_DIR / \"missing_files.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16403cd6",
   "metadata": {},
   "source": [
    "Leak detection (split overlap checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585002a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap train∩val : 0\n",
      "Overlap train∩test: 0\n",
      "Overlap val∩test  : 0\n"
     ]
    }
   ],
   "source": [
    "train_paths = set(train_df[\"path\"].astype(str))\n",
    "val_paths   = set(val_df[\"path\"].astype(str))\n",
    "test_paths  = set(test_df[\"path\"].astype(str))\n",
    "\n",
    "overlap_train_val  = train_paths & val_paths\n",
    "overlap_train_test = train_paths & test_paths\n",
    "overlap_val_test   = val_paths & test_paths\n",
    "\n",
    "print(\"Overlap train∩val :\", len(overlap_train_val))\n",
    "print(\"Overlap train∩test:\", len(overlap_train_test))\n",
    "print(\"Overlap val∩test  :\", len(overlap_val_test))\n",
    "\n",
    "if overlap_train_val or overlap_train_test or overlap_val_test:\n",
    "    overlap_report = {\n",
    "        \"train_val\": sorted(list(overlap_train_val))[:50],\n",
    "        \"train_test\": sorted(list(overlap_train_test))[:50],\n",
    "        \"val_test\": sorted(list(overlap_val_test))[:50],\n",
    "        \"note\": \"Lists truncated to 50 each.\"\n",
    "    }\n",
    "    with open(ARTIFACTS_DIR / \"split_overlaps.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(overlap_report, f, indent=2)\n",
    "    print(\"Saved:\", ARTIFACTS_DIR / \"split_overlaps.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6425d81",
   "metadata": {},
   "source": [
    "See if it opens the image correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddf2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 686/686 [00:00<00:00, 1314.52it/s]\n",
      "100%|██████████| 147/147 [00:00<00:00, 1332.86it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 1360.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unreadable images: 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def open_image_ok(path_str: str) -> tuple[bool, str]:\n",
    "    try:\n",
    "        p = resolve_path(path_str)\n",
    "        with Image.open(p) as im:\n",
    "            im.verify()\n",
    "        return True, \"\"\n",
    "    except Exception as e:\n",
    "        return False, f\"{type(e).__name__}: {e}\"\n",
    "\n",
    "def scan_openability(df: pd.DataFrame, max_items: int | None = None):\n",
    "    errs = []\n",
    "    items = df[\"path\"].astype(str).tolist()\n",
    "    if max_items:\n",
    "        items = items[:max_items]\n",
    "    for p in tqdm(items):\n",
    "        ok, err = open_image_ok(p)\n",
    "        if not ok:\n",
    "            errs.append({\"path\": p, \"error\": err})\n",
    "    return pd.DataFrame(errs)\n",
    "\n",
    "bad_train = scan_openability(train_df)\n",
    "bad_val   = scan_openability(val_df)\n",
    "bad_test  = scan_openability(test_df)\n",
    "\n",
    "print(\"Unreadable images:\", len(bad_train), len(bad_val), len(bad_test))\n",
    "\n",
    "if len(bad_train) + len(bad_val) + len(bad_test) > 0:\n",
    "    bad = pd.concat([\n",
    "        bad_train.assign(split=\"train\"),\n",
    "        bad_val.assign(split=\"val\"),\n",
    "        bad_test.assign(split=\"test\"),\n",
    "    ])\n",
    "    bad.to_csv(ARTIFACTS_DIR / \"unreadable_images.csv\", index=False)\n",
    "    display(bad.head(20))\n",
    "    print(\"Saved:\", ARTIFACTS_DIR / \"unreadable_images.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd700b2",
   "metadata": {},
   "source": [
    "Quick size/mode sanity to check for grayscale vs color images, and size variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc3ca7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode\n",
       "L    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       width  height\n",
       "count   50.0    50.0\n",
       "mean    48.0    48.0\n",
       "std      0.0     0.0\n",
       "min     48.0    48.0\n",
       "25%     48.0    48.0\n",
       "50%     48.0    48.0\n",
       "75%     48.0    48.0\n",
       "max     48.0    48.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample_image_stats(df: pd.DataFrame, n: int = 50, seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    paths = df[\"path\"].astype(str).tolist()\n",
    "    sample = random.sample(paths, k=min(n, len(paths)))\n",
    "\n",
    "    rows = []\n",
    "    for p in sample:\n",
    "        with Image.open(Path(resolve_path(p))) as im:\n",
    "            rows.append({\"path\": p, \"mode\": im.mode, \"width\": im.size[0], \"height\": im.size[1]})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "stats_train = sample_image_stats(train_df, n=50)\n",
    "display(stats_train[\"mode\"].value_counts())\n",
    "display(stats_train[[\"width\",\"height\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfe7e9",
   "metadata": {},
   "source": [
    "Reporting on all the tests done so far for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d46d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts': {'train': 686, 'val': 147, 'test': 148, 'total': 981},\n",
       " 'missing_files': {'train': 0, 'val': 0, 'test': 0},\n",
       " 'overlaps': {'train_val': 0, 'train_test': 0, 'val_test': 0},\n",
       " 'unreadable_images': {'train': 0, 'val': 0, 'test': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = {\n",
    "    \"counts\": {\n",
    "        \"train\": len(train_df),\n",
    "        \"val\": len(val_df),\n",
    "        \"test\": len(test_df),\n",
    "        \"total\": len(train_df) + len(val_df) + len(test_df),\n",
    "    },\n",
    "    \"missing_files\": {\n",
    "        \"train\": int(len(missing_train)),\n",
    "        \"val\": int(len(missing_val)),\n",
    "        \"test\": int(len(missing_test)),\n",
    "    },\n",
    "    \"overlaps\": {\n",
    "        \"train_val\": int(len(overlap_train_val)),\n",
    "        \"train_test\": int(len(overlap_train_test)),\n",
    "        \"val_test\": int(len(overlap_val_test)),\n",
    "    },\n",
    "    \"unreadable_images\": {\n",
    "        \"train\": int(len(bad_train)),\n",
    "        \"val\": int(len(bad_val)),\n",
    "        \"test\": int(len(bad_test)),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(ARTIFACTS_DIR / \"notebook00_integrity_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
